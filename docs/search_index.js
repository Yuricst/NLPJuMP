var documenterSearchIndex = {"docs":
[{"location":"basics.html#Basics-with-NLPSaUT.jl","page":"Basics","title":"Basics with NLPSaUT.jl","text":"","category":"section"},{"location":"basics.html#A-simple-algebraic-NLP","page":"Basics","title":"A simple algebraic NLP","text":"","category":"section"},{"location":"basics.html","page":"Basics","title":"Basics","text":"Let's suppose we would like to solve the following NLP","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"beginaligned\nmin_x_1x_2 quad x_1^2 - x_2\ntextsuch thatquad\nx_1^3 + x_2 - 24 = 0\n\nx_1 + x_2 - 5 leq 0\n\n-03x_1 + x_2 - 2 leq 0\nendaligned","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We first import the necessary modules","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"using GLMakie\nusing Ipopt\nusing JuMP\n\npush!(LOAD_PATH, joinpath(@__DIR__, \"../src/\"))\nusing NLPSaUT","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We now define the problem dimension along with a fitness function that computes the objective, equality, and inequality constraints. ","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"# problem dimensions\nnx = 2                   # number of decision vectors\nnh = 1                   # number of equality constraints\nng = 2                   # number of inequality constraints\nlx = -10*ones(nx,)       # lower bounds on decision variables\nux =  10*ones(nx,)       # upper bounds on decision variables\nx0 = [-1.2, 10]          # initial guess\n\n# fitness function\nfunction f_fitness(x::T...) where {T<:Real}\n\t# objective\n    f = x[1]^2 - x[2]\n    \n    # equality constraints\n    h = zeros(T, 1)\n    h = x[1]^3 + x[2] - 2.4\n\n    # inequality constraints\n    g = zeros(T, 2)\n    g[1] = x[1] + x[2] - 5\n    g[2] = -0.3x[1] + x[2] - 2\n    return [f; h; g]\nend","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"tip: Tip\nWhen defining a fitness function, ensure the following:The returned argument is a 1D array in order f (objective), h (equality constraints, if any), g (inequality constraints, if any).\nInequality constraints are provided the general form g(x) = 0.\nThe input argument signature is f_fitness(x::T...) where {T<:Real} - this is required as long as ForwardDiff.jl is to be used for gradients.\nThe input argument x is a 1D array","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We can now construct a JuMP model. Here, we will use Ipopt.","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"model = NLPSaUT.build_model(Ipopt.Optimizer, f_fitness, nx, nh, ng, lx, ux, x0)\nset_optimizer_attribute(model, \"tol\", 1e-12)\nset_optimizer_attribute(model, \"print_level\", 5)","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We can view the model via println(model), which returns","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"Min fobj(x[1], x[2])\nSubject to\n op_h_1(x[1], x[2]) - 0.0 = 0\n op_g_1(x[1], x[2]) - 0.0 ≤ 0\n op_g_2(x[1], x[2]) - 0.0 ≤ 0\n x[1] ≥ -10\n x[2] ≥ -10\n x[1] ≤ 10\n x[2] ≤ 10","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"and solve it!","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"optimize!(model)","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We can check what we got","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"xopt = value.(model[:x])                # extract optimal decision\n@assert is_solved_and_feasible(model)\nprintln(termination_status(model))\nprintln(\"Decision vector: \")\nprintln(xopt)\nprintln(\"Objective: \")\nprintln(objective_value(model))","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"Let's visualize the results:","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"fig = Figure(size=(500,500))\nax = Axis(fig[1,1], xlabel=\"x1\", ylabel=\"x2\")\nxs_grid = LinRange(-11, 11, 100)\nys_grid = LinRange(-11, 11, 100)\ncontourf!(ax, xs_grid, ys_grid, (x, y) -> f_fitness(x, y)[1], levels=20)\n\n# plot constraints\nlines!(ax, [x for x in xs_grid], [2.4 - x^3 for x in xs_grid], color=:blue)\nfill_between!(ax, xs_grid, maximum(xs_grid) * ones(length(xs_grid)), \n    [0.3x + 2 for x in xs_grid], color=:black, alpha=0.35)\nfill_between!(ax, xs_grid, maximum(xs_grid) * ones(length(xs_grid)), \n    [5 - x for x in xs_grid], color=:black, alpha=0.35)\n\n# plot solution\nscatter!(ax, [value(model[:x][1])], [value(model[:x][2])], markersize=5, color=:red)\n\n# set bounds\nxlims!(ax, minimum(xs_grid), maximum(xs_grid))\nylims!(ax, minimum(ys_grid), maximum(ys_grid))\n\ndisplay(fig)","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"(Image: contour_basics)","category":"page"},{"location":"basics.html#Fitness-function-with-an-ODEProblem-inside","page":"Basics","title":"Fitness function with an ODEProblem inside","text":"","category":"section"},{"location":"basics.html","page":"Basics","title":"Basics","text":"Let us now consider a trajectory design problem, where we need to integrate some dynamics.  Specifically, we will consider the design of a phasing trajectory along a halo orbit with two impulses in the CR3BP dynamics.  Let P denote the orbital period of the halo orbit; we wish to come back to the initial position r_0 with a time of flight of 09P. ","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"Let Delta v denote the initial maneuver vector, and barr and barv denote the initial position and velocity vecor along the halo orbit. Mathematically (with a bit of abuse of notation), this can be written as","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"beginaligned\nmin_Delta v quad  Delta v _2 +  barv - v(09P) _2\ntextsuch thatquad\nbarr - r(09P)\nendaligned","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"where r(09P) and v(09P) are the position and velocity vectors at time t = 09P, obtained by solving the initial value problem","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"beginaligned\ndotr = v\n\ndotv = -dfrac1-mur_1^3r_1 - dfracmur_2^3r_2 - omega times (omega times r) - 2omega times r\n\nr(0) = barr\n\nv(0) = barv + Delta v\nendaligned","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"with omega = 001^T, r_1 = r - -mu00^T, and r_2 = r - 1-mu00^T. ","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We first load necessary modules, then define the dynamics in a compatible form to OrdinaryDiffEq","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"using GLMakie\nusing Ipopt\nusing JuMP\nusing LinearAlgebra\nusing OrdinaryDiffEq\n\ninclude(joinpath(@__DIR__, \"../src/NLPSaUT.jl\"))\n\nfunction cr3bp_rhs!(du,u,p,t)\n    # unpack state\n    x, y, z = u[1], u[2], u[3]\n    vx, vy, vz = u[4], u[5], u[6]\n    # compute distances\n    r1 = sqrt( (x+p[1])^2 + y^2 + z^2 );\n    r2 = sqrt( (x-1+p[1])^2 + y^2 + z^2 );\n    # derivatives of positions\n    du[1] = u[4]\n    du[2] = u[5]\n    du[3] = u[6]\n    # derivatives of velocities\n    du[4] = 2*vy + x - ((1-p[1])/r1^3)*(p[1]+x) + (p[1]/r2^3)*(1-p[1]-x);\n    du[5] = -2*vx + y - ((1-p[1])/r1^3)*y - (p[1]/r2^3)*y;\n    du[6] = -((1-p[1])/r1^3)*z - (p[1]/r2^3)*z;\n    return\nend","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"Let us define the initial conditions, period, and mu for the CR3BP system","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"rv0 = [1.0809931218390707, 0.0, -2.0235953267405354E-01,\n       0.0, -1.9895001215078018E-01, 0.0]\nperiod_0 = 2.3538670417546639E+00\ntspan = [0.0, 0.9*period_0]\nμ = 1.215058560962404e-02\nparams_ode = [μ,]","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We will now define a conveninence method for propagating the trajectory - this will be used inside the fitness function, as well as for plotting later on:","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"base_ode_problem = ODEProblem(cr3bp_rhs!, rv0, tspan, params_ode)\n\nfunction get_trajectory(DV::T...) where {T<:Real}\n    ode_problem = remake(base_ode_problem; u0 = rv0 + [0; 0; 0; DV...])\n    sol = solve(ode_problem, Tsit5(); reltol = 1e-12, abstol = 1e-12)\n    return sol\nend","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We are now ready to define our problem dimension & fitness function","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"nx = 3\nnh = 3\nng = 0\nlx = -0.5 * ones(nx,)\nux =  0.5 * ones(nx,)\nx0 = [0.0, 0.0, 0.0]\n\nfunction f_fitness(DV::T...) where {T<:Real}\n    # integrate trajectory\n    sol = get_trajectory(DV...)\n\n    # final state deviation\n    xf = sol.u[end]\n    \n\t# objective\n    f = norm(DV) + norm(rv0[4:6] - xf[4:6])\n    \n    # equality constraints for final state\n    h = rv0[1:3] - xf[1:3]\n    return [f; h]\nend","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"Let's solve it!","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"\n# get model\norder = 2\ndiff_f = \"forward\"\nmodel = NLPSaUT.build_model(Ipopt.Optimizer, f_fitness, nx, nh, ng, lx, ux, x0; disable_memoize = false)\nset_optimizer_attribute(model, \"tol\", 1e-12)\nset_optimizer_attribute(model, \"print_level\", 5)\nprintln(model)\n\n# run optimizer\noptimize!(model)\nxopt = value.(model[:x])\n\n# checks\n@assert is_solved_and_feasible(model)","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"We can plot the resulting trajectory via","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"# plot\nsol_initialguess = get_trajectory(x0...)\nsol_optimal = get_trajectory(xopt...)\n\nfig = Figure(size=(400,500))\nax = Axis3(fig[1,1]; aspect = :data, xlabel = \"x\", ylabel = \"y\", zlabel = \"z\")\nscatter!(ax, [rv0[1]], [rv0[2]], [rv0[3]], markersize = 10, color = :red)\nlines!(ax, Array(sol_initialguess)[1,:], Array(sol_initialguess)[2,:], Array(sol_initialguess)[3,:],\n       color = :grey, label=\"Initial guess\")\nlines!(ax, Array(sol_optimal)[1,:], Array(sol_optimal)[2,:], Array(sol_optimal)[3,:],\n       color = :red, label=\"Optimal two-impulse phasing trajectory\")\naxislegend(ax)\ndisplay(fig)","category":"page"},{"location":"basics.html","page":"Basics","title":"Basics","text":"(Image: example_cr3bp)","category":"page"},{"location":"api_core.html#Core-routines","page":"Core","title":"Core routines","text":"","category":"section"},{"location":"api_core.html#Construct-model","page":"Core","title":"Construct model","text":"","category":"section"},{"location":"api_core.html","page":"Core","title":"Core","text":"Modules = [NLPSaUT]\nOrder   = [:function, :type]\nPages   = [\n  \"model.jl\",\n]","category":"page"},{"location":"api_core.html#Main.NLPSaUT.build_model!-Tuple{Model, Function, Int64, Int64, Int64, Vector, Vector, Vector}","page":"Core","title":"Main.NLPSaUT.build_model!","text":"build_model!(model::JuMP.Model, f_fitness::Function, nx::Int, nh::Int, ng::Int, lx::Vector, ux::Vector, x0::Vector=nothing)\n\nExtend model for NLP problem via memoized fitness function.\n\nArguments:\n\nmodel::JuMP.Model: model to append objective and constraints\nf_fitness::Function: fitness function, returning [f, h, g]\nnx::Int: number of decision variables \nnh::Int: number of equality constraints \nng::Int: number of inequality constraints \nlx::Vector: lower bounds on decision variables \nux::Vector: upper bounds on decision variables \nx0::Vector: initial guess\nauto_diff::Bool: whether to use automatic differentiation\norder::Int: order of FiniteDifferences, minimum is 2\nfd_type::String: finite-difference method, \"forward\", \"backward\", or \"central\"\n\n\n\n\n\n","category":"method"},{"location":"api_core.html#Main.NLPSaUT.build_model-Tuple{Any, Function, Int64, Int64, Int64, Vector, Vector, Vector}","page":"Core","title":"Main.NLPSaUT.build_model","text":"build_model(f_fitness::Function, nx::Int, nh::Int, ng::Int, lx::Vector, ux::Vector, x0::Vector=nothing, fd_type::Function=nothing, order::Int=2)\n\nBuild model for NLP problem with memoized fitness function.\n\nArguments:\n\noptimizer: optimizer to use with the model\nf_fitness::Function: fitness function, returning [f, h, g]\nnx::Int: number of decision variables \nnh::Int: number of equality constraints \nng::Int: number of inequality constraints \nlx::Vector: lower bounds on decision variables \nux::Vector: upper bounds on decision variables \nx0::Vector: initial guess\nauto_diff::Bool: whether to use automatic differentiation\norder::Int: order of FiniteDifferences, minimum is 2\nfd_type::String: finite-difference method, \"forward\", \"backward\", or \"central\"\n\n\n\n\n\n","category":"method"},{"location":"api_core.html#Memoization","page":"Core","title":"Memoization","text":"","category":"section"},{"location":"api_core.html","page":"Core","title":"Core","text":"Modules = [NLPSaUT]\nOrder   = [:function, :type]\nPages   = [\n  \"memoize.jl\",\n]","category":"page"},{"location":"api_core.html#Main.NLPSaUT.memoize_fitness-Tuple{Function, Int64}","page":"Core","title":"Main.NLPSaUT.memoize_fitness","text":"memoize_fitness(f_fitness::Function, n_outputs::Int)\n\nMemoize fitness function.  Because foo_i is auto-differentiated with ForwardDiff, our cache needs to work when x is a Float64 and a ForwardDiff.Dual.\n\nSee:  https://jump.dev/JuMP.jl/stable/tutorials/nonlinear/tipsandtricks/#Memoization\n\n\n\n\n\n","category":"method"},{"location":"api_core.html#Main.NLPSaUT.memoize_fitness_gradient","page":"Core","title":"Main.NLPSaUT.memoize_fitness_gradient","text":"memoize_fitness_gradient(f_fitness::Function, nfitness::Int, fd_type::Function, order::Int=2)\n\nCreate memoized gradient computation with method specified by fd_type     - fd_type = \"forward\" use FiniteDifferences.forward_fdm()     - fd_type = \"central\" use FiniteDifferences.central_fdm()     - fd_type = \"backward\" use FiniteDifferences.backward_fdm()\n\n\n\n\n\n","category":"function"},{"location":"index.html#NLPSaUT","page":"Home","title":"NLPSaUT","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"The NLPSaUT module constructs a JuMP model for a generic nonlinear program (NLP). The expected use case is solving a differentiable (either analytically or numerically) nonconvex NLP with gradient-based algorithms such as Ipopt or SNOPT. ","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The user is expected to provide a \"fitness function\" (pygmo-style), which evaluates the objective, equality, and inequality constraints.  Derivatives of f_fitness is taken using ForwardDiff.jl (which is the default JuMP behavior according to its docs); as such, f_fitness should be written in a way that is compatiable to ForwardDiff.jl (read here as to why it is ForwardDiff, not ReverseDiff).  For reference, here's the JuMP docs page on common mistakes when using ForwardDiff.jl. ","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"The model constructed by NLPSaUT utilizes memoization to economize on the fitness evaluation (see JuMP Tips and tricks on NLP). ","category":"page"},{"location":"index.html#Quick-start","page":"Home","title":"Quick start","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"git clone this repository\nstart julia-repl\nactivate & instantiate package (first time)","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"pkg> activate .\njulia> using Pkg                # first time only\njulia> Pkg.instantiate()        # first time only","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"run tests","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"(NLPSaUT) pkg> test","category":"page"},{"location":"index.html#Note","page":"Home","title":"Note","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"To use with SNOPT, it's probably better to go through GAMS.jl rather than to use SNOPT7.jl directly (installing SNOPT7.jl currently errors on julia v1.10)","category":"page"}]
}
